[![English](https://img.shields.io/badge/Language-English-blue.svg)](README.en.md)

# ðŸ§¬ Predictor de LocalizaciÃ³n Subcelular de ProteÃ­nas

Un proyecto end-to-end de BioinformÃ¡tica y Machine Learning para predecir la ubicaciÃ³n de una proteÃ­na dentro de la cÃ©lula basÃ¡ndose en su secuencia de aminoÃ¡cidos.

## ðŸŽ¯ Objetivo del proyecto

En la biologÃ­a celular y la ingenierÃ­a genÃ©tica, conocer la **localizaciÃ³n subcelular** de una proteÃ­na es fundamental para entender su funciÃ³n. Una proteÃ­na en el nÃºcleo se comportarÃ¡ de manera muy diferente a una en la mitocondria. El objetivo de este proyecto es desarrollar un sistema automatizado y preciso que, dada una secuencia de aminoÃ¡cidos, pueda predecir en quÃ© compartimento celular residirÃ¡.

Esta herramienta tiene como fin acelerar la investigaciÃ³n y el diseÃ±o de proteÃ­nas sintÃ©ticas, permitiendo a los cientÃ­ficos validar in silicio sus hipÃ³tesis antes de realizar costosos y lentos experimentos en el laboratorio.

## ðŸš€ MetodologÃ­a y EvoluciÃ³n

El proyecto se desarrollÃ³ de manera iterativa, aumentando progresivamente la complejidad y el rendimiento del sistema. Cada fase se centrÃ³ en resolver los cuellos de botella identificados en la fase anterior.

### Fase 1: RecolecciÃ³n de Datos y Modelo Baseline

-   **MÃ©todo:** Se desarrollÃ³ un script para descargar datos de proteÃ­nas de levadura (*Saccharomyces cerevisiae*) desde la base de datos **UniProt**. Las caracterÃ­sticas iniciales fueron la **composiciÃ³n de aminoÃ¡cidos** y se entrenÃ³ un modelo base **Random Forest**.
-   **Problema Encontrado:** El rendimiento era pobre y estaba sesgado hacia las clases mayoritarias. AdemÃ¡s, la API de UniProt presentaba limitaciones tÃ©cnicas.
-   **SoluciÃ³n:** Se implementÃ³ un sistema de **paginaciÃ³n por cursor** para la descarga robusta de datos y una **agrupaciÃ³n jerÃ¡rquica de clases** para crear un conjunto de datos mÃ¡s limpio y balanceado.

### Fase 2: Mejora de CaracterÃ­sticas y Modelos

-   **MÃ©todo:** Se probaron caracterÃ­sticas de **k-mers** (di-pÃ©ptidos) y se escalÃ³ el modelo a algoritmos de **Gradient Boosting** (`LightGBM` y `XGBoost`) para manejar la mayor dimensionalidad.
-   **Problema Encontrado:** Las clases con pocas muestras (desbalance de clases) seguÃ­an siendo un desafÃ­o, limitando el rendimiento general.
-   **SoluciÃ³n:** Se implementÃ³ una estrategia de **ponderaciÃ³n de muestras** (`sample_weight`) para forzar al modelo a prestar mÃ¡s atenciÃ³n a las clases minoritarias durante el entrenamiento.

### Fase 3: CaracterÃ­sticas de Vanguardia con Deep Learning

-   **MÃ©todos:** El salto cualitativo final consistiÃ³ en adoptar un enfoque de **Deep Learning**. Se utilizÃ³ **ESM-2**, un Modelo de Lenguaje de ProteÃ­nas, para generar **embeddings** de cada secuencia. Un embedding es un vector denso que representa el "significado" bioquÃ­mico y evolutivo de la proteÃ­na.
-   **Problema Encontrado:** La generaciÃ³n de embeddings es un proceso computacionalmente intensivo.
-   **SoluciÃ³n:** Se creÃ³ un script dedicado para realizar este pre-procesamiento una Ãºnica vez, guardando los embeddings en un archivo para que el entrenamiento posterior fuera rÃ¡pido.

El siguiente diagrama ilustra el flujo completo del proceso de entrenamiento:

``` mermaid
graph TD
    subgraph "Fase 1: Datos" 
        A[UniProt Database] -->|scripts/download_data.py| B(Datos Crudos: 5,134 proteÃ­nas);
        B --> |src/data_processing.py| C{Datos Procesados\n y Limpios};
        C --> |AgrupaciÃ³n JerÃ¡rquica| D(4,944 proteÃ­nas en 8 clases)
    end
    
    subgraph "Fase 2: CaracterÃ­sticas" 
        D --> |src/embedding_generator.py| E[Modelo ESM-2];
        E --> F(Embeddings Vectoriales);
    end
    
    subgraph "Fase 3: Entrenamiento" 
        F --> |src/train.py| G[DivisiÃ³n 80/20: Train/Test];
        G --> H{Modelo XGBoost\n +\n PonderaciÃ³n de Clases}
        H --> I(Modelo Entrenado:\n protein_location_model.pkl)
    end
```

## ðŸ“Š Resultados Finales

La combinaciÃ³n final de **embeddings de ESM-2** con un modelo **XGBoost** y **ponderaciÃ³n de clases** demostrÃ³ ser la mÃ¡s efectiva. Entrenado sobre un conjunto de datos completo de **5,134 proteÃ­nas** de UniProt, y tras un filtrado que resultÃ³ en **4,994 muestras** para el entrenamiento, el modelo alcanzÃ³ un rendimiento robusto y generalizable.

El modelo final logrÃ³ una **precisiÃ³n general del 64.0%** en el conjunto de prueba.

| Clase                  | Precision | Recall    | F1-Score | Support |
|------------------------|-----------|-----------|----------|---------|
| Cytoplasm              | 0.63      | 0.68      | 0.66     | 311     |
| Endoplasmic Reticulum  | 0.48      | 0.49      | 0.48     | 65      |
| Golgi Apparatus        | 0.2       | 0.07      | 0.11     | 27      |
| Membrane               | 0.76      | 0.73      | 0.74     | 186     |
| Mitochondrion          | 0.71      | 0.59      | 0.65     | 139     |
| Nucleus                | 0.60      | 0.70      | 0.65     | 227     |
| Secreted/Extracellular | 0.79      | 0.69      | 0.73     | 16      |
| Vacuole                | 0.27      | 0.11      | 0.15     | 28      |
| **Weightened Avg**     | **0.63**  | **0.64**  | **0.63** | **999** |

#### VisualizaciÃ³n del Rendimiento

Para comprender mejor el comportamiento del modelo, se generaron las siguientes visualizaciones:

-   **Matriz de ConfusiÃ³n:** Este grÃ¡fico muestra dÃ³nde acierta y dÃ³nde falla el modelo. Los valores en la diagonal principal representan las predicciones correctas. Podemos observar que el modelo es muy robusto para clases como `Membrane` y `Nucleus`, pero aÃºn presenta confusiones en las clases con menos muestras.

![matriz_confusion](reports/figures/confusion_matrix.png)

- **F1-Score por Clase:** Este grÃ¡fico ilustra el rendimiento balanceado (una media de precisiÃ³n y recall) para cada clase. Confirma que el modelo ha aprendido patrones significativos para la mayorÃ­a de las localizaciones, aunque el rendimiento en `Golgi Apparatus` y `Vacuole` indica que se necesitarÃ­an mÃ¡s datos para alcanzar la misma robustez.

![f1_score_por_clase](reports/figures/f1_scores_by_class.png)

## ðŸ› ï¸ Desarrollos Realizados

El estado actual del proyecto es un pipeline de Machine Learning completo y automatizado.

1. **Pipeline Automatizado (`run_pipeline.py`):** Un script ejecutable que permite lanzar todo el proceso (descarga, pre-procesamiento, generaciÃ³n de embeddings y entrenamiento) con un solo comando.
2. **Estructura Modular:** El cÃ³digo estÃ¡ organizado en `src/` con mÃ³dulos separados para el procesamiento de datos, la generaciÃ³n de caracterÃ­sticas y el entrenamiento.
3. **Modelo de Vanguardia:** El sistema utiliza embeddings de proteÃ­nas (ESM-2) y un clasificador XGBoost con ponderaciÃ³n de clases para maximizar el rendimiento.

## ðŸ”® PrÃ³ximos Pasos

El "cerebro" del sistema estÃ¡ completo. Los siguientes pasos se centran en darle un "cuerpo" y ponerlo en producciÃ³n.

1. **Crear una API:** Desarrollar un endpoint con **FastAPI** que reciba una secuencia de proteÃ­na y devuelva la localizaciÃ³n predicha en tiempo real.
2. **Contenerizar con Docker:** Empaquetar toda la aplicaciÃ³n en un contenedor de Docker para garantizar su portabilidad.
3. **Despliegue en la nube:** Publicar el contenedor en un servicio cloud para que la herramienta sea accesible pÃºblicamente.

El siguiente diagrama ilustra cÃ³mo funcionarÃ­a la API una vez desplegada:

```mermaid
sequenceDiagram
    participant Usuario as ðŸ‘¤ Usuario
    participant API as ðŸŒ API (FastAPI)
    participant ESM2 as ðŸ§  Modelo ESM-2
    participant XGBoost as ðŸŒ³ Modelo XGBoost
    participant Encoder as ðŸ·ï¸ LabelEncoder

    Usuario->>API: POST /predict con secuencia: "MDSK..."
    API->>ESM2: Generar embedding para "MDSK..."
    ESM2-->>API: Devuelve vector [0.1, 0.9, ...]
    API->>XGBoost: Predecir con el vector
    XGBoost-->>API: Devuelve predicciÃ³n numÃ©rica (ej. 4)
    API->>Encoder: Decodificar el nÃºmero 4
    Encoder-->>API: Devuelve etiqueta "Mitochondrion"
    API-->>Usuario: JSON: {"predicted_location": "Mitochondrion"}
```